{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter7 二次元画像解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(\"../chapter06/stable-diffusion_柴田真宏_anime.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "> 画像が明るすぎて白飛びが発生している箇所と黒く潰れている箇所は, それぞれR, G, Bの明度値が(255, 255, 255), (0, 0, 0)になっている. このような画素の色を(255, 0, 0)に書き換えて保存することで, 白飛びと黒潰れの領域を可視化するコードを作成せよ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_blank(image):\n",
    "    out_image = image.copy()\n",
    "    out_image = np.where(\n",
    "        ((out_image == np.array([0, 0, 0]))|(out_image == np.array([255, 255, 255]))).all(axis = 2, keepdims= True),\n",
    "        np.array([255, 0, 0]),\n",
    "        out_image)\n",
    "    return out_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, ch = img.shape\n",
    "l = 100\n",
    "m = h - 2*l\n",
    "n = w - 2*l\n",
    "img_blank = img * np.vstack((\n",
    "    np.hstack((np.zeros((l, l, ch)), np.ones((l, n, ch)), np.ones((l, l, ch)))),\n",
    "    np.hstack((np.ones((m, l, ch)), np.ones((m, n, ch)), np.ones((m, l, ch)))),\n",
    "    np.hstack((np.ones((l, l, ch)), np.ones((l, n, ch)), np.ones((l, l, ch))*255))\n",
    "    ))\n",
    "img_blank = np.clip(img_blank, 0, 255).astype(np.uint8)\n",
    "img_red = visualize_blank(img_blank)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (12, 3))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_blank)\n",
    "ax[2].imshow(img_red)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "> 画像のR, G, Bそれぞれの平均値と分散を算出し表示するコードを作成せよ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_moment(image):\n",
    "    for i, c in enumerate([\"R\", \"G\", \"B\"]):\n",
    "        print(f\"{c}: mean {np.mean(image[..., i]):.2f}, var {np.var(image[..., i]):.2f}\")\n",
    "\n",
    "def hist_brightness(image):\n",
    "    _, _, ch = image.shape\n",
    "    fig, ax = plt.subplots(ch, 1)\n",
    "    for i in range(ch):\n",
    "        ax[i].hist(image[..., i].flatten(), bins = 255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_moment(img)\n",
    "hist_brightness(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3\n",
    "> 求まった平均値と分散を使って, 明度変換のパラメータ`a, b`を自動で決定する方法を考えよ.\n",
    "## 3.4\n",
    "> プログラムリスト3.1を変更し, 練習問題3.3で考えた方法で自動的に明度調整を行うコードを作成せよ.\n",
    "```{python}\n",
    "# program list 3.1\n",
    "height, width, channel = dat.shape\n",
    "a=1.5\n",
    "b=-10\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        for ch in range(channel):\n",
    "            k=(int(dat[y][x][ch])-128)*a+128+b\n",
    "            if (k>255):\n",
    "                k=255\n",
    "            elif (k<0):\n",
    "                k=0\n",
    "            dat[y][x][ch]=k\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness(image, a = 64, b = 128):\n",
    "    out_image = image.copy()\n",
    "    _, _, channel = out_image.shape\n",
    "    for i in range(channel):\n",
    "        mean = np.mean(out_image[..., i])\n",
    "        sd = np.std(out_image[..., i])\n",
    "        k = (out_image[..., i] - mean) / sd * a + b\n",
    "        out_image[..., i] = np.clip(k, 0, 255)\n",
    "\n",
    "    return out_image.astype(np.uint8) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_adjust = adjust_brightness(img)\n",
    "rgb_moment(img_adjust)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 3))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_adjust)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_brightness(img)\n",
    "hist_brightness(img_adjust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5\n",
    "> 1次微分フィルタを使ったフィルタ処理を実装し, 自身で準備した画像に対してエッジ検出を行え."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(image, filter):\n",
    "    image = image.copy().astype(np.float32)\n",
    "    \n",
    "    # padding\n",
    "    h, w = filter.shape\n",
    "    pad_h = h // 2\n",
    "    pad_w = w // 2\n",
    "    \n",
    "    image = np.pad(image, [(pad_h, pad_h), (pad_w, pad_w), (0, 0)], \"edge\")\n",
    "    out_image = np.zeros_like(image)\n",
    "    \n",
    "    height, width = out_image.shape[:2]\n",
    "    channel = 1 if len(out_image.shape) == 2 else out_image.shape[2]\n",
    "    \n",
    "    # filtering\n",
    "    for y in range(pad_h, height-pad_h):\n",
    "        for x in range(pad_w, width-pad_w):\n",
    "            for ch in range(channel):\n",
    "                out_image[y, x, ch] = (image[y-pad_h : y+pad_h+1, x-pad_w : x+pad_w+1, ch]*filter).sum()\n",
    "            \n",
    "    out_image = out_image[pad_h : height-pad_h, pad_w : width-pad_w]\n",
    "    return np.clip(out_image, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oned_filter_w = np.array([[0.0, 0.0, 0.0], [-1.0, 0.0, 1.0], [0.0, 0.0, 0.0]])\n",
    "oned_filter_h = oned_filter_w.T\n",
    "\n",
    "img_edge_w = filtering(img, oned_filter_w)\n",
    "img_edge_h = filtering(img, oned_filter_h)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (12, 3))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_edge_w)\n",
    "ax[2].imshow(img_edge_h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prewitt_w = np.array([[-1.0, 0.0, 1.0], [-1.0, 0.0, 1.0], [-1.0, 0.0, 1.0]])\n",
    "prewitt_h = prewitt_w.T\n",
    "\n",
    "img_edge_w = filtering(img, prewitt_w)\n",
    "img_edge_h = filtering(img, prewitt_h)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (12, 3))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_edge_w)\n",
    "ax[2].imshow(img_edge_h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_w = np.array([[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]])\n",
    "sobel_h = sobel_w.T\n",
    "\n",
    "img_edge_w = filtering(img, sobel_w)\n",
    "img_edge_h = filtering(img, sobel_h)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (12, 3))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_edge_w)\n",
    "ax[2].imshow(img_edge_h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6\n",
    "> OpenCVの説明書や解説サイトを参考に, OpenCVライブラリを使ってFAST特徴点を検出してみよ.\n",
    "\n",
    "[docs of OpenCV](https://docs.opencv.org/4.x/df/d0c/tutorial_py_fast.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast = cv2.FastFeatureDetector()\n",
    "kp = fast.detect(img, None)\n",
    "img2 = cv2.drawKeypoints(img, kp, None, color=(0,0,255))\n",
    "\n",
    "fast.setNonmaxSuppression(0)\n",
    "kp = fast.detect(img, None)\n",
    "img3 = cv2.drawKeypoints(img, kp, None, color=(0,0,255))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 3))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img2)\n",
    "ax[2].imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7\n",
    "> 同じ解像度の2枚の画像を入力し, SSDを計算することで2枚の画像の類似度を算出せよ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd(image1, image2):\n",
    "    if image1.shape != image2.shape:\n",
    "        raise AssertionError(\"shapes of images must be the same!!\")\n",
    "\n",
    "    return np.sum((image1 - image2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = io.imread(\"../chapter06/stable-diffusion_柴田真宏_anime_2.png\")\n",
    "ssd(img, img_red), ssd(img, img2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
