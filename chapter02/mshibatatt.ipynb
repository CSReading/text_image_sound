{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter2 言語資源と言語モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "> 上に述べたようにシソーラスやオントロジーには様々なものがある. インターネットを利用してそれらのシソーラスを利用することができるので, それぞれのシソーラスの違いを調べてみよう. どのような違いが見られ, またその違いはなぜ生じるのか考えてみよう."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [WordNet](https://bond-lab.github.io/wnja/jpn/index.html)\n",
    "- [NINJAL](https://clrd.ninjal.ac.jp/goihyo.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"wnjpn.db\"):\n",
    "    os.system(\"wget https://github.com/bond-lab/wnja/releases/download/v1.1/wnjpn.db.gz\")\n",
    "    os.system(\"gzip -d wnjpn.db.gz\")\n",
    "if not os.path.isfile(\"bunruidb.txt\"):\n",
    "    os.system(\"wget https://github.com/masayu-a/WLSP/raw/master/bunruidb.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNet: \n",
    "    def __init__(self) -> None:\n",
    "        self.connect()\n",
    "    \n",
    "    def connect(self) -> None:\n",
    "        self.con = sqlite3.connect(\"wnjpn.db\")\n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "    def close(self) -> None:\n",
    "        self.cur.close()\n",
    "        self.con.close()\n",
    "\n",
    "    def read_sql(self, SQL_statement: str) -> pd.DataFrame:\n",
    "        return pd.read_sql(SQL_statement, self.con) \n",
    "\n",
    "    def show_tables(self, SQL_statement: str) -> list:\n",
    "        res = self.con.execute(\"SELECT table FROM sqlite_master WHERE type = 'table'\")\n",
    "        return res.fetchall()\n",
    "\n",
    "    def thesaurus(self, word: str) -> list[list[str]]:\n",
    "        SQL_statement = f\"\"\"\n",
    "            WITH search_synset AS (\n",
    "                SELECT synset, word.wordid, word.lang\n",
    "                FROM sense \n",
    "                    LEFT JOIN word\n",
    "                        ON sense.wordid = word.wordid\n",
    "                WHERE lemma = '{word}'\n",
    "            )\n",
    "            SELECT DISTINCT sense.synset, lemma\n",
    "            FROM search_synset\n",
    "                LEFT JOIN sense\n",
    "                    ON search_synset.synset = sense.synset\n",
    "                LEFT JOIN word\n",
    "                    ON sense.wordid = word.wordid\n",
    "                        AND search_synset.lang = word.lang\n",
    "        \"\"\"\n",
    "        df = self.read_sql(SQL_statement)\n",
    "        if len(df) == 0:\n",
    "            raise KeyError(f\"{word} not found!!\")\n",
    "        \n",
    "        df = df[(df[\"lemma\"] != word) & (df[\"lemma\"].notna())]\n",
    "        if len(df) == 0:\n",
    "            raise KeyError(f\"thesaurus of {word} not found!!\")\n",
    "\n",
    "        # there may be severals rows for the same word\n",
    "        ret = []\n",
    "        for (v, d) in df.groupby(\"synset\"):\n",
    "            ret.append(d[\"lemma\"].tolist())\n",
    "        \n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NINJAL:\n",
    "    def __init__(self):\n",
    "        colnames = [\n",
    "            \"id\", # レコードID番号\n",
    "            \"headline_id\", # 見出し番号\n",
    "            \"record_kind\", #レコード種別,\n",
    "            \"kind\", # 類,\n",
    "            \"division\", # 部門,\n",
    "            \"item\", # 中項目,\n",
    "            \"class\", # 分類項目,\n",
    "            \"class_id\", # 分類番号,\n",
    "            \"paragraph_id\", # 段落番号,\n",
    "            \"small_paragraph_id\", # 小段落番号,\n",
    "            \"word_id\", # 語番号,\n",
    "            \"headline\", # 見出し,\n",
    "            \"headline_body\", # 見出し本体,\n",
    "            \"read\", # 読み,\n",
    "            \"read_rev\", # 逆読み,\n",
    "        ]\n",
    "        self.df = pd.read_csv(\"bunruidb.txt\", encoding=\"CP932\", names=colnames, header=None)\n",
    "\n",
    "    def thesaurus(self, word: str) -> list[list[str]]:\n",
    "        keys = [\"record_kind\", \"kind\", \"division\", \"item\", \"class_id\", \"paragraph_id\", \"small_paragraph_id\"]\n",
    "        df_word = self.df[self.df[\"headline\"] == word][keys]\n",
    "        if len(df_word) == 0:\n",
    "            raise KeyError(f\"{word} not found!!\")\n",
    "        \n",
    "        df_thesaurus = df_word.merge(self.df, how=\"left\", on=keys)\n",
    "        df_thesaurus = df_thesaurus[df_thesaurus[\"headline\"] != word]\n",
    "        if len(df_thesaurus) == 0:\n",
    "            raise KeyError(f\"thesaurus of {word} not found!!\")\n",
    "        \n",
    "        # there may be severals rows for the same word\n",
    "        ret = []\n",
    "        for (v, d) in df_thesaurus.groupby(keys):\n",
    "            ret.append(d[\"headline\"].tolist())\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['四つ脚',\n",
       "  '毛の荒物',\n",
       "  '獣畜',\n",
       "  '4つ脚',\n",
       "  'アニマル',\n",
       "  '4つ足',\n",
       "  '生物',\n",
       "  '生き物',\n",
       "  '獣',\n",
       "  '珍獣',\n",
       "  '生類',\n",
       "  '生体',\n",
       "  '四つ足',\n",
       "  '鳥獣']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = WordNet()\n",
    "wn.thesaurus(\"動物\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['動物', 'アニマル', '鳥獣', '禽獣', '魚介'],\n",
       " ['畜類', '畜生', '動物', '獣畜'],\n",
       " ['植物体', '動物', '植物']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninja = NINJAL()\n",
    "ninja.thesaurus(\"動物\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 \n",
    "> Nグラム言語モデルで単語列が生起する確率を求めるとき, コーパス中に現れない単語が出現する問題をゼロ頻度問題と呼ぶ. このようなときにどのような対象法が考えられているのだろうか."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3\n",
    "> 近年ではNグラム言語モデル以外にも様々な言語モデルが提案されている. どのような言語モデルが他に存在するのか, 調べてみよう."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://en.wikipedia.org/wiki/Language_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
